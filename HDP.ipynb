{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coherence import eval_coherence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdp_topics(hdp, top_n=10):\n",
    "    '''Wrapper function to extract topics from trained tomotopy HDP model \n",
    "    \n",
    "    ** Inputs **\n",
    "    hdp:obj -> HDPModel trained model\n",
    "    top_n: int -> top n words in topic based on frequencies\n",
    "    \n",
    "    ** Returns **\n",
    "    topics: dict -> per topic, an arrays with top words and associated frequencies \n",
    "    '''\n",
    "    \n",
    "    # Get most important topics by # of times they were assigned (i.e. counts)\n",
    "    sorted_topics = [k for k, v in sorted(enumerate(hdp.get_count_by_topics()), key=lambda x:x[1], reverse=True)]\n",
    "\n",
    "    topics=dict()\n",
    "    \n",
    "    # For topics found, extract only those that are still assigned\n",
    "    for k in sorted_topics:\n",
    "        if not hdp.is_live_topic(k): continue # remove un-assigned topics at the end (i.e. not alive)\n",
    "        topic_wp =[]\n",
    "        for word, prob in hdp.get_topic_words(k, top_n=top_n):\n",
    "            topic_wp.append((word, prob))\n",
    "\n",
    "        topics[k] = topic_wp # store topic word/frequency array\n",
    "        \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sums.txt', 'r') as f:\n",
    "    sums = ast.literal_eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2305"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums_list = [item.split() for item in sums]\n",
    "len(sums_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "term_weight = tp.TermWeight.IDF\n",
    "HDP = tp.HDPModel(tw=term_weight, min_cf=5, rm_top=6, gamma=0.1, eta=0.2,\n",
    "                  alpha=0.1, initial_k=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add docs to train\n",
    "for vec in sums_list:\n",
    "    HDP.add_doc(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs: 2305 , Vocab size: 3255 , Num words: 214561\n"
     ]
    }
   ],
   "source": [
    "# Initiate sampling burn-in  (i.e. discard N first iterations)\n",
    "HDP.burn_in = 100\n",
    "HDP.train(0)\n",
    "print('Num docs:', len(HDP.docs), ', Vocab size:', HDP.num_vocabs,\n",
    "      ', Num words:', HDP.num_words)\n",
    "# print('Removed top words:', hdp.removed_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tLog-likelihood: -21.708408297021368\tNum. of topics: 5\n",
      "Iteration: 1\tLog-likelihood: -21.693367732265916\tNum. of topics: 5\n",
      "Iteration: 2\tLog-likelihood: -21.692122286538122\tNum. of topics: 5\n",
      "Iteration: 3\tLog-likelihood: -21.689517352333738\tNum. of topics: 5\n",
      "Iteration: 4\tLog-likelihood: -21.689856206368574\tNum. of topics: 5\n",
      "Iteration: 5\tLog-likelihood: -21.691685329358712\tNum. of topics: 5\n",
      "Iteration: 6\tLog-likelihood: -21.687985446776775\tNum. of topics: 5\n",
      "Iteration: 7\tLog-likelihood: -21.687567375596345\tNum. of topics: 5\n",
      "Iteration: 8\tLog-likelihood: -21.68451050185152\tNum. of topics: 5\n",
      "Iteration: 9\tLog-likelihood: -21.685256553010362\tNum. of topics: 5\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for i in range(0, 10):\n",
    "    HDP.train(100) # 100 iterations at a time\n",
    "    print('Iteration: {}\\tLog-likelihood: {}\\tNum. of topics: {}'.format(i, HDP.ll_per_word, HDP.live_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics = get_hdp_topics(HDP, top_n=50) # changing top_n changes no. of words displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating topic coherence...\n",
      "Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5682074918558703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_coherence(topics,sums_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = np.array([['Topic_{}_words'.format(str(i)), 'Topic_{}_significance'.format(str(i))] for i in range(5)]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0_words</th>\n",
       "      <th>Topic_0_significance</th>\n",
       "      <th>Topic_1_words</th>\n",
       "      <th>Topic_1_significance</th>\n",
       "      <th>Topic_2_words</th>\n",
       "      <th>Topic_2_significance</th>\n",
       "      <th>Topic_3_words</th>\n",
       "      <th>Topic_3_significance</th>\n",
       "      <th>Topic_4_words</th>\n",
       "      <th>Topic_4_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Topic_0_words, Topic_0_significance, Topic_1_words, Topic_1_significance, Topic_2_words, Topic_2_significance, Topic_3_words, Topic_3_significance, Topic_4_words, Topic_4_significance]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    results['Topic_{}_words'.format(str(i))] = np.array(topics[i]).T[0]\n",
    "    results['Topic_{}_significance'.format(str(i))] = [float(item) for item in np.array(topics[i]).T[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0_words</th>\n",
       "      <th>Topic_0_significance</th>\n",
       "      <th>Topic_1_words</th>\n",
       "      <th>Topic_1_significance</th>\n",
       "      <th>Topic_2_words</th>\n",
       "      <th>Topic_2_significance</th>\n",
       "      <th>Topic_3_words</th>\n",
       "      <th>Topic_3_significance</th>\n",
       "      <th>Topic_4_words</th>\n",
       "      <th>Topic_4_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prostitution</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>vessel</td>\n",
       "      <td>0.021557</td>\n",
       "      <td>applicant</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>appellant</td>\n",
       "      <td>0.010006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prostitute</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>girl</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>smuggle</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>appellant</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>france</td>\n",
       "      <td>0.007201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anonymous</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>complainant</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>siev</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>court</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>irregular</td>\n",
       "      <td>0.007006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>tell</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>crew</td>\n",
       "      <td>0.011002</td>\n",
       "      <td>section</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>smuggle</td>\n",
       "      <td>0.005423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>force</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>mr</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>venture</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>article</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>italy</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_0_words  Topic_0_significance Topic_1_words  Topic_1_significance  \\\n",
       "0  prostitution              0.005627            ms              0.009118   \n",
       "1    prostitute              0.004545          girl              0.006133   \n",
       "2     anonymous              0.004491   complainant              0.005550   \n",
       "3        sexual              0.004296          tell              0.005550   \n",
       "4         force              0.003928            mr              0.005286   \n",
       "\n",
       "  Topic_2_words  Topic_2_significance Topic_3_words  Topic_3_significance  \\\n",
       "0        vessel              0.021557     applicant              0.010408   \n",
       "1       smuggle              0.014508     appellant              0.009013   \n",
       "2          siev              0.011109         court              0.007132   \n",
       "3          crew              0.011002       section              0.006069   \n",
       "4       venture              0.008033       article              0.005321   \n",
       "\n",
       "  Topic_4_words  Topic_4_significance  \n",
       "0     appellant              0.010006  \n",
       "1        france              0.007201  \n",
       "2     irregular              0.007006  \n",
       "3       smuggle              0.005423  \n",
       "4         italy              0.005421  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('HDP_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
