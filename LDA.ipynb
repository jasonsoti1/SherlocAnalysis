{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import ast\n",
    "import numpy as np\n",
    "from coherence import eval_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sums.txt','r') as f:\n",
    "    sums = ast.literal_eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.9, min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>zambia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>zamboanga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3254 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words\n",
       "0        abandon\n",
       "1         abduct\n",
       "2           abet\n",
       "3        ability\n",
       "4           able\n",
       "...          ...\n",
       "3249  yugoslavia\n",
       "3250      zambia\n",
       "3251   zamboanga\n",
       "3252     zealand\n",
       "3253        zone\n",
       "\n",
       "[3254 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.get_feature_names_out(), columns=['Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This can take awhile, we're dealing with a large amount of documents!\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_distribution = LDA.components_ / LDA.components_.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 30 WORDS FOR TOPIC #0\n",
      "['smuggle', 'vessel', 'migrant', 'crew', 'australia', 'later', 'siev', 'venture', 'case', 'mr', 'charge', 'member', 'board', 'indonesian', 'convict', 'states', 'involvement', 'australian', 'intercept', 'indonesia', 'passenger', 'united', 'accuse', 'near', 'authority', 'carry', 'relate', 'island', 'involve', 'reef', 'ashmore', 'paid', 'time', 'apprehend', 'afghan', 'receive', 'left', 'captain', 'involves', 'boat', 'christmas', 'day', 'refer', 'mexico', 'appeal', 'person', 'june', 'arrival', 'background', 'alien']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #1\n",
      "['court', 'traffic', 'criminal', 'human', 'woman', 'case', 'police', 'person', 'child', 'defendant', 'accuse', 'act', 'crime', 'prostitution', 'state', 'charge', 'work', 'applicant', 'law', 'victim', 'investigation', 'order', 'year', 'offence', 'group', 'code', 'exploitation', 'section', 'make', 'commit', 'minor', 'article', 'sentence', 'evidence', 'report', 'force', 'allege', 'plaintiff', 'worker', 'labour', 'file', 'sexual', 'public', 'include', 'appeal', 'convict', 'authority', 'guilty', 'imprisonment', 'high']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #2\n",
      "['migrant', 'defendant', 'smuggle', 'criminal', 'vessel', 'group', 'italy', 'authority', 'border', 'organise', 'transport', 'use', 'police', 'ship', 'spain', 'irregular', 'person', 'boat', 'court', 'evidence', 'water', 'legal', 'travel', 'illegal', 'board', 'individual', 'sea', 'finding', 'hong', 'kong', 'purpose', 'fact', 'member', 'condition', 'austria', 'transfer', 'country', 'include', 'vehicle', 'order', 'commentary', 'cross', 'organize', 'involve', 'carry', 'ascertain', 'activity', 'number', 'rescue', 'national']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #3\n",
      "['appellant', 'migrant', 'accuse', 'france', 'appeal', 'court', 'smuggle', 'passport', 'document', 'defendant', 'national', 'united', 'case', 'uk', 'convict', 'visa', 'entry', 'irregular', 'illegal', 'immigration', 'stay', 'legal', 'kingdom', 'decision', 'travel', 'authority', 'later', 'enter', 'false', 'sentence', 'finding', 'charge', 'evidence', 'commentary', 'provide', 'facilitate', 'assist', 'marriage', 'obtain', 'issue', 'fraudulent', 'fact', 'work', 'refugee', 'asylum', 'residence', 'airport', 'person', 'arrest', 'accommodate']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #4\n",
      "['victim', 'defendant', 'work', 'woman', 'prostitution', 'money', 'accuse', 'force', 'sexual', 'girl', 'tell', 'police', 'transport', 'prostitute', 'day', 'year', 'house', 'use', 'receive', 'recruit', 'ms', 'travel', 'provide', 'service', 'sex', 'time', 'make', 'return', 'job', 'client', 'passport', 'pay', 'offer', 'paid', 'old', 'brothel', 'engage', 'month', 'met', 'city', 'bar', 'court', 'know', 'information', 'purpose', 'order', 'promise', 'arrest', 'person', 'minor']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for index,topic in enumerate(word_distribution):\n",
    "    print(f'THE TOP 30 WORDS FOR TOPIC #{index}')\n",
    "    myDict[cnt] = [[cv.get_feature_names_out()[i], round(topic[i],3)] for i in topic.argsort()]\n",
    "    print(list(reversed([cv.get_feature_names_out()[i] for i in topic.argsort()[-50:]])))\n",
    "    print('\\n')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating topic coherence...\n",
      "Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.622649557633958"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums_list = [item.split() for item in sums]\n",
    "eval_coherence(myDict, sums_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = np.array([['Topic_{}_words'.format(str(i)), 'Topic_{}_significance'.format(str(i))] for i in range(5)]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0_words</th>\n",
       "      <th>Topic_0_significance</th>\n",
       "      <th>Topic_1_words</th>\n",
       "      <th>Topic_1_significance</th>\n",
       "      <th>Topic_2_words</th>\n",
       "      <th>Topic_2_significance</th>\n",
       "      <th>Topic_3_words</th>\n",
       "      <th>Topic_3_significance</th>\n",
       "      <th>Topic_4_words</th>\n",
       "      <th>Topic_4_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Topic_0_words, Topic_0_significance, Topic_1_words, Topic_1_significance, Topic_2_words, Topic_2_significance, Topic_3_words, Topic_3_significance, Topic_4_words, Topic_4_significance]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    results['Topic_{}_words'.format(str(i))] = np.flip(myDict[i][-50:]).T[1]\n",
    "    results['Topic_{}_significance'.format(str(i))] = np.flip(myDict[i][-50:]).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0_words</th>\n",
       "      <th>Topic_0_significance</th>\n",
       "      <th>Topic_1_words</th>\n",
       "      <th>Topic_1_significance</th>\n",
       "      <th>Topic_2_words</th>\n",
       "      <th>Topic_2_significance</th>\n",
       "      <th>Topic_3_words</th>\n",
       "      <th>Topic_3_significance</th>\n",
       "      <th>Topic_4_words</th>\n",
       "      <th>Topic_4_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smuggle</td>\n",
       "      <td>0.045</td>\n",
       "      <td>court</td>\n",
       "      <td>0.016</td>\n",
       "      <td>migrant</td>\n",
       "      <td>0.044</td>\n",
       "      <td>appellant</td>\n",
       "      <td>0.028</td>\n",
       "      <td>victim</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vessel</td>\n",
       "      <td>0.042</td>\n",
       "      <td>traffic</td>\n",
       "      <td>0.013</td>\n",
       "      <td>defendant</td>\n",
       "      <td>0.027</td>\n",
       "      <td>migrant</td>\n",
       "      <td>0.018</td>\n",
       "      <td>defendant</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>migrant</td>\n",
       "      <td>0.034</td>\n",
       "      <td>criminal</td>\n",
       "      <td>0.011</td>\n",
       "      <td>smuggle</td>\n",
       "      <td>0.018</td>\n",
       "      <td>accuse</td>\n",
       "      <td>0.017</td>\n",
       "      <td>work</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crew</td>\n",
       "      <td>0.024</td>\n",
       "      <td>human</td>\n",
       "      <td>0.01</td>\n",
       "      <td>criminal</td>\n",
       "      <td>0.013</td>\n",
       "      <td>france</td>\n",
       "      <td>0.014</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>australia</td>\n",
       "      <td>0.024</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.009</td>\n",
       "      <td>vessel</td>\n",
       "      <td>0.011</td>\n",
       "      <td>appeal</td>\n",
       "      <td>0.013</td>\n",
       "      <td>prostitution</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_0_words Topic_0_significance Topic_1_words Topic_1_significance  \\\n",
       "0       smuggle                0.045         court                0.016   \n",
       "1        vessel                0.042       traffic                0.013   \n",
       "2       migrant                0.034      criminal                0.011   \n",
       "3          crew                0.024         human                 0.01   \n",
       "4     australia                0.024         woman                0.009   \n",
       "\n",
       "  Topic_2_words Topic_2_significance Topic_3_words Topic_3_significance  \\\n",
       "0       migrant                0.044     appellant                0.028   \n",
       "1     defendant                0.027       migrant                0.018   \n",
       "2       smuggle                0.018        accuse                0.017   \n",
       "3      criminal                0.013        france                0.014   \n",
       "4        vessel                0.011        appeal                0.013   \n",
       "\n",
       "  Topic_4_words Topic_4_significance  \n",
       "0        victim                0.049  \n",
       "1     defendant                0.042  \n",
       "2          work                 0.02  \n",
       "3         woman                0.014  \n",
       "4  prostitution                0.009  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('LDA_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
