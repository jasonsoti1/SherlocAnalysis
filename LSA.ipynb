{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from coherence import eval_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sums.txt\",\"r\") as f:\n",
    "    sums = ast.literal_eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc_clean):\n",
    "    \"\"\"\n",
    "    Input  : clean document\n",
    "    Purpose: create term dictionary of our courpus and Converting list of documents (corpus) into Document Term Matrix\n",
    "    Output : term dictionary and Document Term Matrix\n",
    "    \"\"\"\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    # generate LDA model\n",
    "    return dictionary,doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gensim_lsa_model(doc_clean,number_of_topics):\n",
    "    \"\"\"\n",
    "    Input  : clean document, number of topics and number of words associated with each topic\n",
    "    Purpose: create LSA model using gensim\n",
    "    Output : return LSA model\n",
    "    \"\"\"\n",
    "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
    "    # generate LSA model\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "#     print(lsamodel.print_topics(num_topics=number_of_topics, num_words=words))\n",
    "    return lsamodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_list = [item.split() for item in sums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSA = create_gensim_lsa_model(sums_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 30 WORDS FOR TOPIC #0\n",
      "['defendant' 'victim' 'work' 'accuse' 'woman' 'migrant' 'money' 'police'\n",
      " 'court' 'prostitution' 'tell' 'sexual' 'transport' 'use' 'day' 'time'\n",
      " 'force' 'prostitute' 'year' 'make' 'house' 'criminal' 'provide' 'smuggle'\n",
      " 'person' 'receive' 'travel' 'case' 'girl' 'passport' 'charge' 'traffic'\n",
      " 'service' 'month' 'sex' 'ms' 'return' 'client' 'order' 'mr' 'later'\n",
      " 'state' 'know' 'paid' 'arrest' 'home' 'information' 'stay' 'evidence'\n",
      " 'group']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #1\n",
      "['accuse' 'defendant' 'victim' 'migrant' 'drug' 'work' 'time' 'make'\n",
      " 'smuggle' 'tell' 'house' 'money' 'girl' 'complainant' 'police' 'client'\n",
      " 'person' 'state' 'sex' 'sexual' 'day' 'know' 'child' 'woman' 'later'\n",
      " 'testify' 'case' 'stay' 'say' 'vessel' 'man' 'evidence' 'ms' 'use' 'mr'\n",
      " 'appellant' 'return' 'charge' 'court' 'arrive' 'mother' 'live' 'criminal'\n",
      " 'want' 'anonymous' 'officer' 'left' 'group' 'home' 'act']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #2\n",
      "['migrant' 'victim' 'smuggle' 'defendant' 'accuse' 'vessel' 'criminal'\n",
      " 'group' 'work' 'authority' 'italy' 'irregular' 'organise' 'appellant'\n",
      " 'sexual' 'drug' 'member' 'tell' 'board' 'money' 'legal' 'sex' 'venture'\n",
      " 'appeal' 'case' 'united' 'illegal' 'crew' 'entry' 'finding' 'water'\n",
      " 'france' 'court' 'convict' 'prostitute' 'client' 'ms' 'charge' 'boat'\n",
      " 'individual' 'girl' 'document' 'ship' 'prostitution' 'carry' 'involve'\n",
      " 'commentary' 'siev' 'house' 'evidence']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #3\n",
      "['defendant' 'accuse' 'work' 'woman' 'ms' 'anonymous' 'victim' 'mr'\n",
      " 'australia' 'brothel' 'drug' 'criminal' 'debt' 'day' 'case' 'club'\n",
      " 'migrant' 'travel' 'smuggle' 'complainant' 'thailand' 'appellant'\n",
      " 'vessel' 'service' 'testify' 'court' 'sex' 'poland' 'arrive' 'visa'\n",
      " 'group' 'receive' 'sydney' 'australian' 'usd' 'contract' 'house'\n",
      " 'prostitution' 'child' 'escape' 'member' 'authority' 'order' 'au'\n",
      " 'brought' 'pay' 'belarus' 'organise' 'parent' 'client']\n",
      "\n",
      "\n",
      "THE TOP 30 WORDS FOR TOPIC #4\n",
      "['victim' 'defendant' 'woman' 'anonymous' 'work' 'migrant' 'smuggle'\n",
      " 'accuse' 'vessel' 'ms' 'criminal' 'italy' 'group' 'transport' 'brothel'\n",
      " 'girl' 'club' 'poland' 'available' 'organise' 'prostitute' 'information'\n",
      " 'tell' 'day' 'passport' 'crew' 'member' 'money' 'client' 'receive'\n",
      " 'operation' 'belarus' 'month' 'republic' 'siev' 'sex' 'usd' 'dancer'\n",
      " 'year' 'venture' 'contract' 'return' 'service' 'boat' 'debt' 'live'\n",
      " 'hong' 'spain' 'kong' 'later']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'THE TOP 30 WORDS FOR TOPIC #{i}')\n",
    "    myDict[i] = [[item.split('*')[1].replace('\"','').strip(), float(item.split('*')[0])] for item in LSA.print_topics(num_words = 50)[i][1].split('+')]\n",
    "    print(np.array(myDict[i]).T[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating topic coherence...\n",
      "Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28511379073924903"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_coherence(myDict, sums_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = np.array([['Topic_{}_words'.format(str(i)), 'Topic_{}_significance'.format(str(i))] for i in range(5)]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0_words</th>\n",
       "      <th>Topic_0_significance</th>\n",
       "      <th>Topic_1_words</th>\n",
       "      <th>Topic_1_significance</th>\n",
       "      <th>Topic_2_words</th>\n",
       "      <th>Topic_2_significance</th>\n",
       "      <th>Topic_3_words</th>\n",
       "      <th>Topic_3_significance</th>\n",
       "      <th>Topic_4_words</th>\n",
       "      <th>Topic_4_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Topic_0_words, Topic_0_significance, Topic_1_words, Topic_1_significance, Topic_2_words, Topic_2_significance, Topic_3_words, Topic_3_significance, Topic_4_words, Topic_4_significance]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    results['Topic_{}_words'.format(str(i))] = np.array(myDict[i]).T[0]\n",
    "    results['Topic_{}_significance'.format(str(i))] = np.array(myDict[i]).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0_words</th>\n",
       "      <th>Topic_0_significance</th>\n",
       "      <th>Topic_1_words</th>\n",
       "      <th>Topic_1_significance</th>\n",
       "      <th>Topic_2_words</th>\n",
       "      <th>Topic_2_significance</th>\n",
       "      <th>Topic_3_words</th>\n",
       "      <th>Topic_3_significance</th>\n",
       "      <th>Topic_4_words</th>\n",
       "      <th>Topic_4_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>defendant</td>\n",
       "      <td>0.569</td>\n",
       "      <td>accuse</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>migrant</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>defendant</td>\n",
       "      <td>-0.479</td>\n",
       "      <td>victim</td>\n",
       "      <td>-0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>victim</td>\n",
       "      <td>0.531</td>\n",
       "      <td>defendant</td>\n",
       "      <td>0.394</td>\n",
       "      <td>victim</td>\n",
       "      <td>0.381</td>\n",
       "      <td>accuse</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>defendant</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work</td>\n",
       "      <td>0.208</td>\n",
       "      <td>victim</td>\n",
       "      <td>0.309</td>\n",
       "      <td>smuggle</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>work</td>\n",
       "      <td>0.302</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuse</td>\n",
       "      <td>0.15</td>\n",
       "      <td>migrant</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>defendant</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.282</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.125</td>\n",
       "      <td>drug</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>accuse</td>\n",
       "      <td>0.215</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.244</td>\n",
       "      <td>work</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_0_words Topic_0_significance Topic_1_words Topic_1_significance  \\\n",
       "0     defendant                0.569        accuse               -0.625   \n",
       "1        victim                0.531     defendant                0.394   \n",
       "2          work                0.208        victim                0.309   \n",
       "3        accuse                 0.15       migrant               -0.149   \n",
       "4         woman                0.125          drug               -0.141   \n",
       "\n",
       "  Topic_2_words Topic_2_significance Topic_3_words Topic_3_significance  \\\n",
       "0       migrant               -0.569     defendant               -0.479   \n",
       "1        victim                0.381        accuse               -0.451   \n",
       "2       smuggle               -0.291          work                0.302   \n",
       "3     defendant               -0.241         woman                0.282   \n",
       "4        accuse                0.215            ms                0.244   \n",
       "\n",
       "  Topic_4_words Topic_4_significance  \n",
       "0        victim               -0.582  \n",
       "1     defendant                0.391  \n",
       "2         woman                 0.29  \n",
       "3     anonymous                 0.25  \n",
       "4          work                0.237  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('LSA_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
